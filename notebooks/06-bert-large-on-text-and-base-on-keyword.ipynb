{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-18T18:26:36.856002Z",
     "start_time": "2025-02-18T18:26:36.852625Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizer, get_scheduler\n",
    "from disaster_prediction.utils import KeyedDataset\n",
    "from disaster_prediction.dataset import load_raw_train_df, load_raw_val_df, load_raw_test_df\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:03:33.316780Z",
     "start_time": "2025-02-18T18:03:33.313648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text_bert = BertModel.from_pretrained('google-bert/bert-large-uncased')\n",
    "        self.text_bert_no_hidden = 1024\n",
    "\n",
    "        self.keyword_bert = BertModel.from_pretrained('google-bert/bert-base-uncased')\n",
    "        self.keyword_bert_no_hidden = 768\n",
    "\n",
    "        self.head = nn.Sequential(nn.LazyLinear(512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.LazyLinear(2))\n",
    "\n",
    "    def forward(self, text_input_ids: torch.Tensor,\n",
    "                text_attention_mask: torch.Tensor,\n",
    "                keyword_input_ids: torch.Tensor,\n",
    "                keyword_attention_mask: torch.Tensor,\n",
    "                labels: torch.Tensor = None):\n",
    "        text_outputs = self.text_bert(input_ids=text_input_ids, attention_mask=text_attention_mask)\n",
    "        text_hidden_layer = text_outputs['pooler_output']\n",
    "\n",
    "        keyword_outputs = self.keyword_bert(input_ids=keyword_input_ids, attention_mask=keyword_attention_mask)\n",
    "        keyword_hidden_layer = keyword_outputs['pooler_output']\n",
    "\n",
    "        full_hidden_layer = torch.cat((text_hidden_layer, keyword_hidden_layer), dim=1)\n",
    "\n",
    "        logits = self.head(full_hidden_layer)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = nn.functional.cross_entropy(logits, labels)\n",
    "            return {'loss': loss, 'logits': logits}\n",
    "        else:\n",
    "            return {'logits': logits}"
   ],
   "id": "f40513fc802dfee7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:03:33.321354Z",
     "start_time": "2025-02-18T18:03:33.319093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataset(df: pd.DataFrame, include_labels=True) -> KeyedDataset:\n",
    "    df['keyword'] = df['keyword'].fillna('')\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('google-bert/bert-large-uncased', do_lower_case=True)\n",
    "    encoded_dict = tokenizer(df['text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "    text_input_ids = encoded_dict['input_ids']\n",
    "    text_attention_mask = encoded_dict['attention_mask']\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-uncased', do_lower_case=True)\n",
    "    encoded_dict = tokenizer(df['keyword'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "    keyword_input_ids = encoded_dict['input_ids']\n",
    "    keyword_attention_mask = encoded_dict['attention_mask']\n",
    "\n",
    "    if include_labels:\n",
    "        labels = torch.tensor(df['target'].tolist())\n",
    "        return KeyedDataset(text_input_ids=text_input_ids,\n",
    "                            text_attention_mask=text_attention_mask,\n",
    "                            keyword_input_ids=keyword_input_ids,\n",
    "                            keyword_attention_mask=keyword_attention_mask,\n",
    "                            labels=labels)\n",
    "    else:\n",
    "        return KeyedDataset(text_input_ids=text_input_ids,\n",
    "                            text_attention_mask=text_attention_mask,\n",
    "                            keyword_input_ids=keyword_input_ids,\n",
    "                            keyword_attention_mask=keyword_attention_mask)"
   ],
   "id": "11dbb360aa214fe2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:03:33.328707Z",
     "start_time": "2025-02-18T18:03:33.325126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model: nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          eval_dataloader: torch.utils.data.DataLoader = None,\n",
    "          device: torch.device = torch.device('cpu'),\n",
    "          lr: float = 5e-5,\n",
    "          epochs: int = 4):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    num_training_steps = len(train_dataloader) * epochs\n",
    "    lr_scheduler = get_scheduler('linear', optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "    progress = tqdm(range(num_training_steps))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs['loss']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress.update()\n",
    "            progress.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        if eval_dataloader is not None:\n",
    "            model.eval()\n",
    "            predictions_list = []\n",
    "            labels_list = []\n",
    "            with torch.no_grad():\n",
    "                for batch in eval_dataloader:\n",
    "                    batch = {key: value.to(device) for key, value in batch.items()}\n",
    "                    outputs = model(**batch)\n",
    "                    predictions = outputs['logits'].argmax(dim=1)\n",
    "                    predictions_list.extend(predictions.tolist())\n",
    "                    labels_list.extend(batch['labels'].tolist())\n",
    "            f1 = f1_score(labels_list, predictions_list)\n",
    "            print(f'EPOCH {epoch + 1}/{epochs} F1: {f1}')"
   ],
   "id": "8d6277dfbae5071b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:03:37.253250Z",
     "start_time": "2025-02-18T18:03:33.332403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = load_raw_train_df()\n",
    "val_df = load_raw_val_df()\n",
    "\n",
    "train_dataset = create_dataset(train_df)\n",
    "val_dataset = create_dataset(val_df)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = Model()\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using cuda')\n",
    "else:\n",
    "    print('Using cpu')"
   ],
   "id": "4f787ae6ad1ebe16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:23:29.602657Z",
     "start_time": "2025-02-18T18:03:37.263441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train(model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        eval_dataloader=val_dataloader,\n",
    "        device=device,\n",
    "        lr=5e-5,\n",
    "        epochs=4)"
   ],
   "id": "49b1a47261039c28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/860 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c92f44cb1e5744d8b5c9ecd951935cd8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/4 F1: 0.8016997167138811\n",
      "EPOCH 2/4 F1: 0.806697108066971\n",
      "EPOCH 3/4 F1: 0.8145896656534954\n",
      "EPOCH 4/4 F1: 0.8190184049079755\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:24:04.650745Z",
     "start_time": "2025-02-18T18:24:04.643593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_model(model: nn.Module, path: str):\n",
    "    torch.save(model.state_dict(), path)"
   ],
   "id": "c088f6080e107d89",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:24:59.701675Z",
     "start_time": "2025-02-18T18:24:57.756227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = os.path.join('../models', 'bert-large-on-text-and-base-on-keyword.pt')\n",
    "\n",
    "save_model(model, model_path)"
   ],
   "id": "91b57698b8c24830",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:27:48.900618Z",
     "start_time": "2025-02-18T18:27:48.896330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_df(df: pd.DataFrame, model: nn.Module, model_path: str) -> pd.DataFrame:\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    dataset = create_dataset(df, include_labels=False)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            predictions.extend(outputs['logits'].argmax(dim=1).tolist())\n",
    "    df['target'] = predictions\n",
    "    return df[['id', 'target']]"
   ],
   "id": "d7494a975bc34b36",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:28:35.124580Z",
     "start_time": "2025-02-18T18:27:52.102472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = load_raw_test_df()\n",
    "results = predict_df(test_df, model, model_path)\n",
    "results"
   ],
   "id": "5b7d443608355686",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:29:19.409990Z",
     "start_time": "2025-02-18T18:29:19.402936Z"
    }
   },
   "cell_type": "code",
   "source": "results.to_csv(os.path.join('../data', 'submissions', 'bert-large-on-text-and-base-on-keyword.csv'), index=False)",
   "id": "88425737f3d2ecc0",
   "outputs": [],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
